The file named 'transformer_class' contains the class 'Transformer'.<br>
The file 'tokenizer_subword' includes a tokenizer algorithm. Use a corpus of texts to create tokens and train the model to tokenize words.

The other files are different versions of training the transformer to generate texts.

